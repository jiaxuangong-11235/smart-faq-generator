{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9e46363-9286-4adc-a629-eef2e24ba858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-6.4.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting markdown\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/gongjiaxuan/Desktop/acon/miniconda3/envs/faq/lib/python3.10/site-packages (from openai) (4.10.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/gongjiaxuan/Desktop/acon/miniconda3/envs/faq/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.12.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Requirement already satisfied: sniffio in /Users/gongjiaxuan/Desktop/acon/miniconda3/envs/faq/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/gongjiaxuan/Desktop/acon/miniconda3/envs/faq/lib/python3.10/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/gongjiaxuan/Desktop/acon/miniconda3/envs/faq/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/gongjiaxuan/Desktop/acon/miniconda3/envs/faq/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /Users/gongjiaxuan/Desktop/acon/miniconda3/envs/faq/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/gongjiaxuan/Desktop/acon/miniconda3/envs/faq/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/gongjiaxuan/Desktop/acon/miniconda3/envs/faq/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.41.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.12.0-cp310-cp310-macosx_11_0_arm64.whl (319 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp310-cp310-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-6.4.0-py3-none-any.whl (329 kB)\n",
      "Downloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, pypdf, pydantic-core, markdown, jiter, distro, annotated-types, pydantic, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [openai] 9/10\u001b[0m [openai]c]core]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.12.0 markdown-3.10 openai-2.8.1 pydantic-2.12.4 pydantic-core-2.41.5 pypdf-6.4.0 tqdm-4.67.1 typing-inspection-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai pypdf markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6e634ab-c5f2-4cf7-87a0-a79d23067611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"My_OPEN_API_KEY\"\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84fb7d40-0420-457c-a6e0-70caec4066e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today in Jupyter? If you have any questions or need help with your code, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello from Jupyter!\"}]\n",
    ")\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e70ab874-bae9-4c44-847c-2138ad2ac19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pypdf import PdfReader\n",
    "from typing import List, Dict\n",
    "import json, textwrap, markdown\n",
    "\n",
    "def read_pdf_file(path: Path, max_chars: int = 20000) -> str:\n",
    "    reader = PdfReader(str(path))\n",
    "    texts = []\n",
    "    total = 0\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text() or \"\"\n",
    "        if not page_text:\n",
    "            continue\n",
    "        if total + len(page_text) > max_chars:\n",
    "            page_text = page_text[: max_chars - total]\n",
    "        texts.append(page_text)\n",
    "        total += len(page_text)\n",
    "        if total >= max_chars:\n",
    "            break\n",
    "    return \"\\n\".join(texts)\n",
    "\n",
    "FAQ_SYSTEM_PROMPT = \"\"\"You are an AI assistant that generates helpful, clear FAQs (question–answer pairs) from documents.\n",
    "\n",
    "Given a document, you will:\n",
    "- Identify 3–7 of the most important, likely user questions.\n",
    "- Provide concise, accurate answers based ONLY on the given text.\n",
    "- Avoid speculation.\n",
    "Return valid JSON:\n",
    "[\n",
    "  {\"question\": \"...\", \"answer\": \"...\"},\n",
    "  ...\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "FAQ_USER_PROMPT_TEMPLATE = \"\"\"DOCUMENT:\n",
    "\n",
    "{chunk}\n",
    "\n",
    "Based ONLY on this document content, generate 3–7 FAQ-style question and answer pairs.\n",
    "Return ONLY valid JSON in the specified format.\n",
    "\"\"\"\n",
    "\n",
    "def call_llm_generate_faqs_one_chunk(text: str) -> List[Dict[str, str]]:\n",
    "    user_prompt = FAQ_USER_PROMPT_TEMPLATE.format(chunk=text)\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": FAQ_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\n",
    "    raw = resp.choices[0].message.content.strip()\n",
    "\n",
    "    try:\n",
    "        start = raw.index(\"[\")\n",
    "        end = raw.rindex(\"]\") + 1\n",
    "        raw_json = raw[start:end]\n",
    "    except ValueError:\n",
    "        raw_json = raw\n",
    "\n",
    "    try:\n",
    "        data = json.loads(raw_json)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"JSON decode failed. Raw output:\")\n",
    "        print(raw)\n",
    "        return []\n",
    "\n",
    "    faqs: List[Dict[str, str]] = []\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            q = str(item.get(\"question\", \"\")).strip()\n",
    "            a = str(item.get(\"answer\", \"\")).strip()\n",
    "            if q and a:\n",
    "                faqs.append({\"question\": q, \"answer\": a})\n",
    "    return faqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d624ff91-ee47-4536-af79-fbbd0aae976e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text length: 20006\n",
      "\n",
      "Q1: What is LLM-as-a-Judge?\n",
      "A1: LLM-as-a-Judge refers to the use of Large Language Models (LLMs) to evaluate objects, actions, or decisions based on predefined rules, criteria, or preferences, encompassing roles such as graders, evaluators, critics, and verifiers.\n",
      "\n",
      "\n",
      "Q2: What are the main challenges in implementing LLM-as-a-Judge systems?\n",
      "A2: The main challenges include the absence of a systematic review leading to fragmented understanding and inconsistent practices, as well as ensuring the reliability of evaluations aligned with established standards.\n",
      "\n",
      "\n",
      "Q3: How does the paper propose to enhance the reliability of LLM-as-a-Judge systems?\n",
      "A3: The paper explores strategies to enhance reliability by improving consistency, mitigating biases, and adapting to diverse assessment scenarios, along with proposing methodologies for evaluating the reliability of these systems.\n",
      "\n",
      "\n",
      "Q4: What methodologies are suggested for evaluating LLM-as-a-Judge systems?\n",
      "A4: The paper examines metrics, datasets, and methodologies used to evaluate LLM-as-a-Judge systems, highlighting potential sources of bias and methods for their mitigation.\n",
      "\n",
      "\n",
      "Q5: What practical applications of LLM-as-a-Judge are discussed in the paper?\n",
      "A5: The paper discusses practical applications of LLM-as-a-Judge in various domains, including machine learning and high-stakes evaluation scenarios.\n",
      "\n",
      "\n",
      "Q6: What is the significance of the novel benchmark introduced in the paper?\n",
      "A6: The novel benchmark is designed specifically for evaluating LLM-as-a-Judge systems, facilitating systematic reliability assessment and uncovering key trade-offs such as robustness versus sensitivity.\n",
      "\n",
      "\n",
      "Q7: Where can additional resources related to LLM-as-a-Judge be accessed?\n",
      "A7: Additional resources related to LLM-as-a-Judge can be accessed at https://awesome-llm-as-a-judge.github.io/.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs_dir = Path(\"documents\")\n",
    "\n",
    "doc_path = docs_dir / \"LLM as a judge.pdf\"  \n",
    "text = read_pdf_file(doc_path, max_chars=20000)\n",
    "print(\"Loaded text length:\", len(text))\n",
    "\n",
    "faqs = call_llm_generate_faqs_one_chunk(text)\n",
    "\n",
    "for i, faq in enumerate(faqs, 1):\n",
    "    print(f\"\\nQ{i}: {faq['question']}\\nA{i}: {faq['answer']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c537072-a36d-4677-8d2c-962607ae808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##another documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d758a03-f7b1-4686-b3b8-c50ffa17b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import textwrap, markdown\n",
    "\n",
    "output_dir = Path(\"faq_outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def faqs_to_markdown(title: str, faqs: List[Dict[str, str]]) -> str:\n",
    "    lines = [f\"# FAQs for {title}\", \"\"]\n",
    "    for idx, faq in enumerate(faqs, start=1):\n",
    "        lines.append(f\"## Q{idx}. {faq['question']}\")\n",
    "        lines.append(\"\")\n",
    "        wrapped_answer = textwrap.fill(faq[\"answer\"], width=80)\n",
    "        lines.append(wrapped_answer)\n",
    "        lines.append(\"\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def save_markdown_and_html(out_dir: Path, doc_name: str, faqs: List[Dict[str, str]]):\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    md_text = faqs_to_markdown(doc_name, faqs)\n",
    "    md_path = out_dir / f\"{doc_name}_faqs.md\"\n",
    "    md_path.write_text(md_text, encoding=\"utf-8\")\n",
    "    print(\"Markdown saved to:\", md_path)\n",
    "\n",
    "    html_body = markdown.markdown(md_text)\n",
    "    html_template = f\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "  <meta charset=\"utf-8\">\n",
    "  <title>FAQs for {doc_name}</title>\n",
    "</head>\n",
    "<body>\n",
    "{html_body}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "    html_path = out_dir / f\"{doc_name}_faqs.html\"\n",
    "    html_path.write_text(html_template, encoding=\"utf-8\")\n",
    "    print(\"HTML saved to:\", html_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa7db0d2-943c-4b15-9b7c-2bcdd38fc9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing: LLM as a judge.pdf ===\n",
      "Loaded text length: 20006\n",
      "Generated 6 FAQs.\n",
      "Markdown saved to: faq_outputs/LLM as a judge_faqs.md\n",
      "HTML saved to: faq_outputs/LLM as a judge_faqs.html\n",
      "\n",
      "=== Processing: Generative AI project ideas.pdf ===\n",
      "Loaded text length: 13950\n",
      "Generated 7 FAQs.\n",
      "Markdown saved to: faq_outputs/Generative AI project ideas_faqs.md\n",
      "HTML saved to: faq_outputs/Generative AI project ideas_faqs.html\n",
      "\n",
      "=== Processing: Module 7 Homework.pdf ===\n",
      "Loaded text length: 5385\n",
      "Generated 7 FAQs.\n",
      "Markdown saved to: faq_outputs/Module 7 Homework_faqs.md\n",
      "HTML saved to: faq_outputs/Module 7 Homework_faqs.html\n",
      "\n",
      "=== Processing: NeurIPS-2023-judging-llm-as-a-judge-with-mt-bench-and-chatbot-arena-Paper-Datasets_and_Benchmarks.pdf ===\n",
      "Loaded text length: 20004\n",
      "Generated 7 FAQs.\n",
      "Markdown saved to: faq_outputs/NeurIPS-2023-judging-llm-as-a-judge-with-mt-bench-and-chatbot-arena-Paper-Datasets_and_Benchmarks_faqs.md\n",
      "HTML saved to: faq_outputs/NeurIPS-2023-judging-llm-as-a-judge-with-mt-bench-and-chatbot-arena-Paper-Datasets_and_Benchmarks_faqs.html\n"
     ]
    }
   ],
   "source": [
    "docs_dir = Path(\"documents\")\n",
    "output_dir = Path(\"faq_outputs\")\n",
    "\n",
    "doc_files = [\n",
    "    \"LLM as a judge.pdf\",\n",
    "    \"Generative AI project ideas.pdf\",\n",
    "    \"Module 7 Homework.pdf\",\n",
    "    \"NeurIPS-2023-judging-llm-as-a-judge-with-mt-bench-and-chatbot-arena-Paper-Datasets_and_Benchmarks.pdf\",\n",
    "]\n",
    "\n",
    "for fname in doc_files:\n",
    "    doc_path = docs_dir / fname\n",
    "    print(f\"\\n=== Processing: {fname} ===\")\n",
    "    text = read_pdf_file(doc_path, max_chars=20000)\n",
    "    print(\"Loaded text length:\", len(text))\n",
    "\n",
    "    faqs = call_llm_generate_faqs_one_chunk(text)\n",
    "    print(f\"Generated {len(faqs)} FAQs.\")\n",
    "\n",
    "    save_markdown_and_html(output_dir, doc_path.stem, faqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c648ce03-56af-4a31-8277-e5be74dbbc46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
